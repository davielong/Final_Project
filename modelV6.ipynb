{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f22ee45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare the imports for building our neural network and displaying our data \n",
    "import PIL\n",
    "import os\n",
    "import h5py\n",
    "import sys\n",
    "import random\n",
    "import csv\n",
    "import cv2\n",
    "import fnmatch\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import kerastuner as kt\n",
    "from shutil import copyfile\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy import asarray\n",
    "from numpy import savetxt\n",
    "from PIL import Image\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten, Activation, BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from matplotlib import image\n",
    "from os import listdir\n",
    "from sklearn.metrics import classification_report\n",
    "from keras import optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "\n",
    "# set the input and outpout Dirs\n",
    "data_dir = 'C:\\\\Users\\davie\\Desktop\\Final_Project\\FYP\\HCurve'\n",
    "Output = 'C:\\\\Users\\davie\\Desktop\\Final_Project\\FYP\\Processed_Data\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30561174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config settings \n",
    "num_epochs = 15\n",
    "bsize = 50\n",
    "EARLY_STOPPING_PATIENCE = 5\n",
    "input_shape = (32, 32, 3)\n",
    "n_classes = 23\n",
    "class_names = ['ABDMJ', 'Agen', 'Allaple', 'Autoit', 'Berbew', 'Bitman', 'Dinwod', 'Dorkbot', \n",
    "               'Dridex', 'Emotet', 'Fsysna', 'Hematite', 'InstallMonster', 'Oberal', 'Picsys', \n",
    "               'Salgorea', 'Scar', 'Sfone', 'Shifu', 'Socks', 'Sytro', 'Vilsel', 'Vobfus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f0e42bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_plot(H):\n",
    "    # plot the training loss and accuracy\n",
    "    plt.style.use(\"ggplot\")\n",
    "    plt.figure()\n",
    "    plt.plot(H.history[\"loss\"], label=\"train_loss\")\n",
    "    plt.plot(H.history[\"val_loss\"], label=\"val_loss\")\n",
    "    plt.plot(H.history[\"accuracy\"], label=\"train_acc\")\n",
    "    plt.plot(H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "    plt.title(\"Training Loss and Accuracy\")\n",
    "    plt.xlabel(\"Epoch #\")\n",
    "    plt.ylabel(\"Loss/Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.savefig(Output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b73abbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9818, 32, 32, 3)\n",
      "(3273, 32, 32, 3)\n",
      "(9818,)\n",
      "(3273,)\n"
     ]
    }
   ],
   "source": [
    "# load and examine the shape of the data \n",
    "X_train = np.load(Output+'xtrain32x32.npy')\n",
    "Y_train = np.load(Output+'ytrain32x32.npy')\n",
    "X_test = np.load(Output+'xtest32x32.npy')\n",
    "Y_test = np.load(Output+'ytest32x32.npy')\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05e4ea7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before one-hot encoding:  (9818,)\n",
      "Shape after one-hot encoding:  (9818, 23)\n"
     ]
    }
   ],
   "source": [
    "# one-hot encoding using keras\n",
    "print(\"Shape before one-hot encoding: \", Y_train.shape)\n",
    "Y_train = np_utils.to_categorical(Y_train, n_classes)\n",
    "Y_test = np_utils.to_categorical(Y_test, n_classes)\n",
    "print(\"Shape after one-hot encoding: \", Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68cb6687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize an early stopping callback to prevent the model from\n",
    "# overfitting/spending too much time training with minimal gains\n",
    "es = EarlyStopping(monitor=\"val_loss\",patience=EARLY_STOPPING_PATIENCE,restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b55e07eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    # building a linear stack of layers with the sequential model\n",
    "    model = Sequential()\n",
    "    # convolutional layer\n",
    "    model.add(Conv2D(50, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu', input_shape=(32, 32, 3)))\n",
    "    # convolutional layer\n",
    "    model.add(Conv2D(75, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    # convolutional layer\n",
    "    model.add(Conv2D(125, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    # convolutional layer\n",
    "    model.add(Conv2D(150, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    # convolutional layer\n",
    "    model.add(Conv2D(175, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    # flatten output\n",
    "    model.add(Flatten())\n",
    "    # hidden layer\n",
    "    model.add(Dense(500, activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(250, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(125, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    # output layer\n",
    "    model.add(Dense(23, activation='softmax'))\n",
    "\n",
    "    # initialize the learning rate choices and optimizer\n",
    "    lr = hp.Choice(\"learning_rate\",values=[1e-1, 1e-2, 1e-3])\n",
    "    opt = Adam(learning_rate=lr)\n",
    "    # compile the model\n",
    "    model.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    # return the model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36d354a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] instantiating a hyperband tuner object...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Anaconda\\lib\\site-packages\\kerastuner\\engine\\hypermodel.py\", line 104, in build\n",
      "    model = self.hypermodel.build(hp)\n",
      "  File \"<ipython-input-7-e9c9f33a0c9b>\", line 38, in build_model\n",
      "    model.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
      "  File \"C:\\Users\\davie\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 548, in compile\n",
      "    self.optimizer = self._get_optimizer(optimizer)\n",
      "  File \"C:\\Users\\davie\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 586, in _get_optimizer\n",
      "    return tf.nest.map_structure(_get_single_optimizer, optimizer)\n",
      "  File \"C:\\Users\\davie\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\nest.py\", line 867, in map_structure\n",
      "    structure[0], [func(*x) for x in entries],\n",
      "  File \"C:\\Users\\davie\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\nest.py\", line 867, in <listcomp>\n",
      "    structure[0], [func(*x) for x in entries],\n",
      "  File \"C:\\Users\\davie\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 577, in _get_single_optimizer\n",
      "    opt = optimizers.get(opt)\n",
      "  File \"C:\\Users\\davie\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\optimizers.py\", line 132, in get\n",
      "    raise ValueError(\n",
      "ValueError: Could not interpret optimizer identifier: <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x0000024D4EED0F40>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid model 0/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Anaconda\\lib\\site-packages\\kerastuner\\engine\\hypermodel.py\", line 104, in build\n",
      "    model = self.hypermodel.build(hp)\n",
      "  File \"<ipython-input-7-e9c9f33a0c9b>\", line 38, in build_model\n",
      "    model.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
      "  File \"C:\\Users\\davie\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 548, in compile\n",
      "    self.optimizer = self._get_optimizer(optimizer)\n",
      "  File \"C:\\Users\\davie\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 586, in _get_optimizer\n",
      "    return tf.nest.map_structure(_get_single_optimizer, optimizer)\n",
      "  File \"C:\\Users\\davie\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\nest.py\", line 867, in map_structure\n",
      "    structure[0], [func(*x) for x in entries],\n",
      "  File \"C:\\Users\\davie\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\nest.py\", line 867, in <listcomp>\n",
      "    structure[0], [func(*x) for x in entries],\n",
      "  File \"C:\\Users\\davie\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 577, in _get_single_optimizer\n",
      "    opt = optimizers.get(opt)\n",
      "  File \"C:\\Users\\davie\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\optimizers.py\", line 132, in get\n",
      "    raise ValueError(\n",
      "ValueError: Could not interpret optimizer identifier: <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x0000024D4EEBA190>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid model 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Anaconda\\lib\\site-packages\\kerastuner\\engine\\hypermodel.py\", line 104, in build\n",
      "    model = self.hypermodel.build(hp)\n",
      "  File \"<ipython-input-7-e9c9f33a0c9b>\", line 38, in build_model\n",
      "    model.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
      "  File \"C:\\Users\\davie\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 548, in compile\n",
      "    self.optimizer = self._get_optimizer(optimizer)\n",
      "  File \"C:\\Users\\davie\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 586, in _get_optimizer\n",
      "    return tf.nest.map_structure(_get_single_optimizer, optimizer)\n",
      "  File \"C:\\Users\\davie\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\nest.py\", line 867, in map_structure\n",
      "    structure[0], [func(*x) for x in entries],\n",
      "  File \"C:\\Users\\davie\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\nest.py\", line 867, in <listcomp>\n",
      "    structure[0], [func(*x) for x in entries],\n",
      "  File \"C:\\Users\\davie\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 577, in _get_single_optimizer\n",
      "    opt = optimizers.get(opt)\n",
      "  File \"C:\\Users\\davie\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\optimizers.py\", line 132, in get\n",
      "    raise ValueError(\n",
      "ValueError: Could not interpret optimizer identifier: <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x0000024D4EEC6460>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid model 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Anaconda\\lib\\site-packages\\kerastuner\\engine\\hypermodel.py\", line 104, in build\n",
      "    model = self.hypermodel.build(hp)\n",
      "  File \"<ipython-input-7-e9c9f33a0c9b>\", line 38, in build_model\n",
      "    model.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
      "  File \"C:\\Users\\davie\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 548, in compile\n",
      "    self.optimizer = self._get_optimizer(optimizer)\n",
      "  File \"C:\\Users\\davie\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 586, in _get_optimizer\n",
      "    return tf.nest.map_structure(_get_single_optimizer, optimizer)\n",
      "  File \"C:\\Users\\davie\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\nest.py\", line 867, in map_structure\n",
      "    structure[0], [func(*x) for x in entries],\n",
      "  File \"C:\\Users\\davie\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\nest.py\", line 867, in <listcomp>\n",
      "    structure[0], [func(*x) for x in entries],\n",
      "  File \"C:\\Users\\davie\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 577, in _get_single_optimizer\n",
      "    opt = optimizers.get(opt)\n",
      "  File \"C:\\Users\\davie\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\optimizers.py\", line 132, in get\n",
      "    raise ValueError(\n",
      "ValueError: Could not interpret optimizer identifier: <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x0000024D4EEB7190>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid model 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Anaconda\\lib\\site-packages\\kerastuner\\engine\\hypermodel.py\", line 104, in build\n",
      "    model = self.hypermodel.build(hp)\n",
      "  File \"<ipython-input-7-e9c9f33a0c9b>\", line 38, in build_model\n",
      "    model.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
      "  File \"C:\\Users\\davie\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 548, in compile\n",
      "    self.optimizer = self._get_optimizer(optimizer)\n",
      "  File \"C:\\Users\\davie\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 586, in _get_optimizer\n",
      "    return tf.nest.map_structure(_get_single_optimizer, optimizer)\n",
      "  File \"C:\\Users\\davie\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\nest.py\", line 867, in map_structure\n",
      "    structure[0], [func(*x) for x in entries],\n",
      "  File \"C:\\Users\\davie\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\nest.py\", line 867, in <listcomp>\n",
      "    structure[0], [func(*x) for x in entries],\n",
      "  File \"C:\\Users\\davie\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 577, in _get_single_optimizer\n",
      "    opt = optimizers.get(opt)\n",
      "  File \"C:\\Users\\davie\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\optimizers.py\", line 132, in get\n",
      "    raise ValueError(\n",
      "ValueError: Could not interpret optimizer identifier: <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x0000024D4EEB6730>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid model 4/5\n",
      "Invalid model 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Anaconda\\lib\\site-packages\\kerastuner\\engine\\hypermodel.py\", line 104, in build\n",
      "    model = self.hypermodel.build(hp)\n",
      "  File \"<ipython-input-7-e9c9f33a0c9b>\", line 38, in build_model\n",
      "    model.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
      "  File \"C:\\Users\\davie\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 548, in compile\n",
      "    self.optimizer = self._get_optimizer(optimizer)\n",
      "  File \"C:\\Users\\davie\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 586, in _get_optimizer\n",
      "    return tf.nest.map_structure(_get_single_optimizer, optimizer)\n",
      "  File \"C:\\Users\\davie\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\nest.py\", line 867, in map_structure\n",
      "    structure[0], [func(*x) for x in entries],\n",
      "  File \"C:\\Users\\davie\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\nest.py\", line 867, in <listcomp>\n",
      "    structure[0], [func(*x) for x in entries],\n",
      "  File \"C:\\Users\\davie\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 577, in _get_single_optimizer\n",
      "    opt = optimizers.get(opt)\n",
      "  File \"C:\\Users\\davie\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\optimizers.py\", line 132, in get\n",
      "    raise ValueError(\n",
      "ValueError: Could not interpret optimizer identifier: <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x0000024D4EEE22E0>\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Too many failed attempts to build model.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\kerastuner\\engine\\hypermodel.py\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self, hp)\u001b[0m\n\u001b[0;32m    103\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mmaybe_distribute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribution_strategy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m                     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m             \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-e9c9f33a0c9b>\u001b[0m in \u001b[0;36mbuild_model\u001b[1;34m(hp)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;31m# compile the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"categorical_crossentropy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"accuracy\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m     \u001b[1;31m# return the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mcompile\u001b[1;34m(self, optimizer, loss, metrics, loss_weights, weighted_metrics, run_eagerly, steps_per_execution, **kwargs)\u001b[0m\n\u001b[0;32m    547\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 548\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_optimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    549\u001b[0m       self.compiled_loss = compile_utils.LossesContainer(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_get_optimizer\u001b[1;34m(self, optimizer)\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_get_single_optimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    866\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 867\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    868\u001b[0m       expand_composites=expand_composites)\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    866\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 867\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    868\u001b[0m       expand_composites=expand_composites)\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_get_single_optimizer\u001b[1;34m(opt)\u001b[0m\n\u001b[0;32m    576\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_single_optimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 577\u001b[1;33m       \u001b[0mopt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    578\u001b[0m       if (loss_scale is not None and\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\optimizers.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(identifier)\u001b[0m\n\u001b[0;32m    131\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m     raise ValueError(\n\u001b[0m\u001b[0;32m    133\u001b[0m         'Could not interpret optimizer identifier: {}'.format(identifier))\n",
      "\u001b[1;31mValueError\u001b[0m: Could not interpret optimizer identifier: <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x0000024D4EEE22E0>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-46978c74e72e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"[INFO] instantiating a hyperband tuner object...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtuner\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHyperband\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"val_accuracy\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfactor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mOutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\kerastuner\\tuners\\hyperband.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, hypermodel, objective, max_epochs, factor, hyperband_iterations, seed, hyperparameters, tune_new_entries, allow_new_entries, **kwargs)\u001b[0m\n\u001b[0;32m    342\u001b[0m             \u001b[0mtune_new_entries\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtune_new_entries\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m             allow_new_entries=allow_new_entries)\n\u001b[1;32m--> 344\u001b[1;33m         super(Hyperband, self).__init__(\n\u001b[0m\u001b[0;32m    345\u001b[0m             \u001b[0moracle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moracle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    346\u001b[0m             \u001b[0mhypermodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\kerastuner\\engine\\multi_execution_tuner.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, oracle, hypermodel, executions_per_trial, **kwargs)\u001b[0m\n\u001b[0;32m     56\u001b[0m                  \u001b[0mexecutions_per_trial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m                  **kwargs):\n\u001b[1;32m---> 58\u001b[1;33m         super(MultiExecutionTuner, self).__init__(\n\u001b[0m\u001b[0;32m     59\u001b[0m             oracle, hypermodel, **kwargs)\n\u001b[0;32m     60\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moracle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\kerastuner\\engine\\tuner.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, oracle, hypermodel, max_model_size, optimizer, loss, metrics, distribution_strategy, directory, project_name, logger, tuner_id, overwrite)\u001b[0m\n\u001b[0;32m     98\u001b[0m                 distribution_strategy=distribution_strategy)\n\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m         super(Tuner, self).__init__(oracle=oracle,\n\u001b[0m\u001b[0;32m    101\u001b[0m                                     \u001b[0mhypermodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m                                     \u001b[0mdirectory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\kerastuner\\engine\\base_tuner.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, oracle, hypermodel, directory, project_name, logger, overwrite)\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_display\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuner_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moracle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_populate_initial_space\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0moverwrite\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tuner_fname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\kerastuner\\engine\\base_tuner.py\u001b[0m in \u001b[0;36m_populate_initial_space\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    103\u001b[0m         \"\"\"\n\u001b[0;32m    104\u001b[0m         \u001b[0mhp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_space\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_space\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\kerastuner\\engine\\hypermodel.py\u001b[0m in \u001b[0;36m_build_wrapper\u001b[1;34m(self, hp, *args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;31m# to the search space.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[0mhp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\kerastuner\\engine\\hypermodel.py\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self, hp)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_max_fail_streak\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m                     raise RuntimeError(\n\u001b[0m\u001b[0;32m    113\u001b[0m                         'Too many failed attempts to build model.')\n\u001b[0;32m    114\u001b[0m                 \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Too many failed attempts to build model."
     ]
    }
   ],
   "source": [
    "print(\"[INFO] instantiating a hyperband tuner object...\")\n",
    "tuner = kt.Hyperband(build_model,objective=\"val_accuracy\",max_epochs=num_epochs,factor=3,seed=42,directory=Output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bb936b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform the hyperparameter search\n",
    "print(\"[INFO] performing hyperparameter search...\")\n",
    "tuner.search(x=X_train, y=Y_train, validation_data=(X_test, Y_test), batch_size=bsize, callbacks=[es], epochs=num_epochs)\n",
    "# grab the best hyperparameters\n",
    "bestHP = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(\"[INFO] optimal number of filters in conv_1 layer: {}\".format(bestHP.get(\"conv_1\")))\n",
    "print(\"[INFO] optimal number of filters in conv_2 layer: {}\".format(bestHP.get(\"conv_2\")))\n",
    "print(\"[INFO] optimal number of units in dense layer: {}\".format(bestHP.get(\"dense_units\")))\n",
    "print(\"[INFO] optimal learning rate: {:.4f}\".format(bestHP.get(\"learning_rate\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dd1ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the best model and train it\n",
    "print(\"[INFO] training the best model...\")\n",
    "model = tuner.hypermodel.build(bestHP)\n",
    "H = model.fit(x=trainX, y=trainY, validation_data=(testX, testY), batch_size=bsize,epochs=num_epochs, callbacks=[es], verbose=1)\n",
    "# evaluate the network\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predictions = model.predict(x=testX, batch_size=32)\n",
    "print(classification_report(testY.argmax(axis=1),predictions.argmax(axis=1), target_names=class_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be2e396",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cef6caa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00ca1df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55cd6ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af62bac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# building the input vector from the 32x32 pixels\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "# normalizing the data to help with the training\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42926de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff5c175",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e4b2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize an early stopping callback to prevent the model from\n",
    "# overfitting/spending too much time training with minimal gains\n",
    "es = EarlyStopping(monitor=\"val_loss\",patience=EARLY_STOPPING_PATIENCE,restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61ba35e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81abe4d5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# training the model for 15 epochs with a batch size of 50 as there are memory constraints and tweeking the params\n",
    "history = model.fit(X_train, Y_train, batch_size=100, epochs=num_epochs, validation_data=(X_test, Y_test))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1e7233",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# evaluate the model and print the score to screen \n",
    "trainingscores = model.evaluate(X_train, Y_train, verbose=0)\n",
    "testingscores = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"[INFO] evaluating network\")\n",
    "predictions = model.predict(X_test, batch_size=100)\n",
    "print(\"training scores are below \\n\")\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], trainingscores[1]*100))\n",
    "print(\"testing scores are below \\n\")\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], testingscores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baadcba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_test.argmax(axis=1), predictions.argmax(axis=1), target_names=class_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878b2347",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Declare vars for the plotting of figures \n",
    "accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(len(accuracy))\n",
    "\n",
    "# overall model scoreing \n",
    "plt.plot(val_loss, 'r', loss, 'b', val_accuracy, 'g', accuracy, 'y')\n",
    "label = 'R = val_loss', 'B = loss', 'G = val_accuracy', 'Y = accuarcy'\n",
    "plt.title('Model Overview')\n",
    "plt.legend(label)\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.show()\n",
    "\n",
    "# Training output \n",
    "plt.plot(epochs, accuracy, label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracy, label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.show()\n",
    "\n",
    "# testing output \n",
    "plt.plot(epochs, loss, label='Training loss')\n",
    "plt.plot(epochs, val_loss, label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc7b875",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(Output + \"modelReFIT6.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8863bd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myfypenv",
   "language": "python",
   "name": "myfypenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
