{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f22ee45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras imports for the dataset and building our neural network\n",
    "import tensorflow as tf\n",
    "import PIL\n",
    "import os\n",
    "import h5py\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import csv\n",
    "import cv2\n",
    "import fnmatch\n",
    "from shutil import copyfile\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy import asarray\n",
    "from numpy import savetxt\n",
    "from PIL import Image\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\n",
    "from keras.utils import np_utils\n",
    "from matplotlib import image\n",
    "from os import listdir\n",
    "\n",
    "\n",
    "data_dir = 'C:\\\\Users\\davie\\Desktop\\Final_Project\\HCurve'\n",
    "Output = 'C:\\\\Users\\davie\\Desktop\\Final_Project\\FYP\\Processed_Data\\\\'\n",
    "\n",
    "# load all images in a directory\n",
    "loaded_images = []\n",
    "labels = []\n",
    "stats = []\n",
    "def find_dirs(directory, pattern):\n",
    "    for item in os.listdir(directory):\n",
    "        if os.path.isdir(os.path.join(directory, item)):\n",
    "            if fnmatch.fnmatch(item, pattern):\n",
    "                filename = os.path.join(directory, item)\n",
    "                yield filename\n",
    "                \n",
    "def find_files(directory, pattern):\n",
    "    for item in os.listdir(directory):\n",
    "        if os.path.isfile(os.path.join(directory, item)):\n",
    "            if fnmatch.fnmatch(item, pattern):\n",
    "                filename = os.path.join(directory, item)\n",
    "                stats.append(directory)\n",
    "                if 'ABDMJ' in directory: labels.append(0)\n",
    "                elif  'Agen' in directory: labels.append(1)# changes from Agent.BDJM for labeling reasons\n",
    "                elif  'Allaple'  in directory: labels.append(2)\n",
    "                elif  'Autoit'  in directory: labels.append(3)\n",
    "                elif  'Berbew'  in directory: labels.append(4)\n",
    "                elif  'Bitman'  in directory: labels.append(5)\n",
    "                elif  'Dinwod' in directory: labels.append(6)\n",
    "                elif  'Dorkbot'  in directory: labels.append(7)\n",
    "                elif  'Dridex'  in directory: labels.append(8)\n",
    "                elif  'Emotet'  in directory: labels.append(9)\n",
    "                elif  'Fsysna'  in directory: labels.append(10)\n",
    "                elif  'Hematite'  in directory: labels.append(11)\n",
    "                elif  'InstallMonster'  in directory: labels.append(12)\n",
    "                elif  'Oberal'  in directory: labels.append(13)\n",
    "                elif  'Picsys'  in directory: labels.append(14)\n",
    "                elif  'Salgorea'  in directory: labels.append(15)\n",
    "                elif  'Scar'  in directory: labels.append(16)\n",
    "                elif  'Sfone'  in directory: labels.append(17)\n",
    "                elif  'Shifu'  in directory: labels.append(18)\n",
    "                elif  'Socks'  in directory: labels.append(19)\n",
    "                elif  'Sytro'  in directory: labels.append(20)\n",
    "                elif  'Vilsel'  in directory: labels.append(21)\n",
    "                elif  'Vobfus' in directory : labels.append(22)\n",
    "                yield filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7f6e3204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "runtime = True\n",
    "while runtime == True:\n",
    "    for filedir in find_dirs(data_dir, '*'):\n",
    "            for filename in find_files(filedir, '*'):              \n",
    "                # Read RGB image\n",
    "                img_data = cv2.imread(filename) \n",
    "                loaded_images.append(img_data)\n",
    "    print(\"Done\")\n",
    "    runtime = False;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a23470d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output img with window name as 'image'\n",
    "#cv2.imshow('image', loaded_images[0])\n",
    "# Maintain output window utill\n",
    "class_names = ['ABDMJ', 'Agen', 'Allaple', 'Autoit', 'Berbew', 'Bitman', 'Dinwod', 'Dorkbot', \n",
    "               'Dridex', 'Emotet', 'Fsysna', 'Hematite', 'InstallMonster', 'Oberal', 'Picsys', \n",
    "               'Salgorea', 'Scar', 'Sfone', 'Shifu', 'Socks', 'Sytro', 'Vilsel', 'Vobfus']# user presses a key\n",
    "#cv2.waitKey(0)        \n",
    "# Destroying present windows on screen\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "aee38a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "statsArr = np.array(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e7f97ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lastArr = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8bdf1ddd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for row in statsArr:\n",
    "    for c in class_names:\n",
    "        sampleTag = row[48:]\n",
    "        lastArr.append(sampleTag) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e3d46ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = pd.DataFrame(lastArr,columns=['SampleName'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "69fcb227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SampleName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>301093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>26220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       SampleName\n",
       "count      301093\n",
       "unique         22\n",
       "top             o\n",
       "freq        26220"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ad299317",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['ABDMJ', 'Agen', 'Allaple', 'Autoit', 'Berbew', 'Bitman', 'Dinwod',\\n       'Dorkbot', 'Dridex', 'Emotet', 'Fsysna', 'Hematite', 'InstallMonster',\\n       'Oberal', 'Picsys', 'Salgorea', 'Scar', 'Sfone', 'Shifu', 'Socks',\\n       'Sytro', 'Vilsel', 'Vobfus'],\\n      dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-dcebbff4bbcc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdfs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ABDMJ'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Agen'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Allaple'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Autoit'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Berbew'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Bitman'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Dinwod'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Dorkbot'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Dridex'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Emotet'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Fsysna'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Hematite'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'InstallMonster'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Oberal'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Picsys'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Salgorea'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Scar'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Sfone'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Shifu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Socks'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Sytro'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Vilsel'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Vobfus'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"sampleName\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3028\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3029\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3030\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3032\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1264\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1266\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1267\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1268\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1306\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmissing\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1307\u001b[0m                 \u001b[0maxis_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1308\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1309\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1310\u001b[0m             \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['ABDMJ', 'Agen', 'Allaple', 'Autoit', 'Berbew', 'Bitman', 'Dinwod',\\n       'Dorkbot', 'Dridex', 'Emotet', 'Fsysna', 'Hematite', 'InstallMonster',\\n       'Oberal', 'Picsys', 'Salgorea', 'Scar', 'Sfone', 'Shifu', 'Socks',\\n       'Sytro', 'Vilsel', 'Vobfus'],\\n      dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "dfs[['ABDMJ', 'Agen', 'Allaple', 'Autoit', 'Berbew', 'Bitman', 'Dinwod', 'Dorkbot', 'Dridex', 'Emotet', 'Fsysna', 'Hematite', 'InstallMonster', 'Oberal', 'Picsys', 'Salgorea', 'Scar', 'Sfone', 'Shifu', 'Socks', 'Sytro', 'Vilsel', 'Vobfus']].groupby(\"sampleName\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "552cb223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABDMJ\n"
     ]
    }
   ],
   "source": [
    "print(lastArr[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e7e0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "imsARR = np.array(loaded_images)\n",
    "labsARR = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44259b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(imsARR, labsARR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55cd6ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af62bac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # building the input vector from the 256x256 pixels\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "# normalizing the data to help with the training\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42926de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding using keras' numpy-related utilities\n",
    "n_classes = 23\n",
    "class_names = ['ABDMJ', 'Agen', 'Allaple', 'Autoit', 'Berbew', 'Bitman', 'Dinwod', 'Dorkbot', \n",
    "               'Dridex', 'Emotet', 'Fsysna', 'Hematite', 'InstallMonster', 'Oberal', 'Picsys', \n",
    "               'Salgorea', 'Scar', 'Sfone', 'Shifu', 'Socks', 'Sytro', 'Vilsel', 'Vobfus']\n",
    "print(\"Shape before one-hot encoding: \", Y_train.shape)\n",
    "Y_train = np_utils.to_categorical(Y_train, n_classes)\n",
    "Y_test = np_utils.to_categorical(Y_test, n_classes)\n",
    "print(\"Shape after one-hot encoding: \", Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7adba37",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X_train), X_train.shape)\n",
    "print(len(Y_train), Y_train.shape)\n",
    "print(len(X_test), X_test.shape)\n",
    "print(len(Y_test), Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff5c175",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# building a linear stack of layers with the sequential model\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e4b2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convolutional layer\n",
    "model.add(Conv2D(50, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu', input_shape=(256, 256, 3)))\n",
    "# convolutional layer\n",
    "model.add(Conv2D(75, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "# convolutional layer\n",
    "model.add(Conv2D(125, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61ba35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten output\n",
    "model.add(Flatten())\n",
    "# hidden layer\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "# output layer\n",
    "model.add(Dense(23, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81abe4d5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# compiling the sequential model\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "# training the model for 10 epochs\n",
    "history = model.fit(X_train, Y_train, batch_size=30, epochs=10, validation_data=(X_test, Y_test))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1e7233",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainingscores = model.evaluate(X_train, Y_train, verbose=0)\n",
    "testingscores = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"training scores are below \\n\")\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], trainingscores[1]*100))\n",
    "print(\"testing scores are below \\n\")\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], testingscores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878b2347",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = model.history.history['accuracy']\n",
    "val_accuracy = model.history.history['val_accuracy']\n",
    "loss = model.history.history['loss']\n",
    "val_loss = model.history.history['val_loss']\n",
    "epochs = range(len(accuracy))\n",
    "\n",
    "plt.plot(val_loss, 'r', loss, 'b', val_accuracy, 'g', accuracy, 'y')\n",
    "label = 'R = val_loss', 'B = loss', 'G = val_accuracy', 'Y = accuarcy'\n",
    "plt.title('Model Overview')\n",
    "plt.legend(label)\n",
    "plt.show()\n",
    "plt.plot(epochs, accuracy, label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracy, label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, label='Training loss')\n",
    "plt.plot(epochs, val_loss, label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc7b875",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(Output + \"modelReFIT.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myfypenv",
   "language": "python",
   "name": "myfypenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
